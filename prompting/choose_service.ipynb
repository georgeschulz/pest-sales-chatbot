{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import OpenAIChat\n",
    "import sys\n",
    "pd.options.mode.chained_assignment = None\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain import PromptTemplate, LLMChain, VectorDBQA\n",
    "from langchain.chains import TransformChain, SequentialChain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "import re\n",
    "import json\n",
    "import stripe\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "import asyncio\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules/')\n",
    "openai.api_key = os.getenv('OPENAI_KEY')\n",
    "key = os.getenv('OPENAI_KEY')\n",
    "\n",
    "from Generator import Generator\n",
    "from Extractor import Extractor\n",
    "from PromptPath import PromptPath\n",
    "from GenExtract import GenExtract\n",
    "from Property import Property\n",
    "from NaturalLanguagePool import NaturalLanguagePool\n",
    "from DynamicChatHistory import DynamicChatHistory\n",
    "from Conversation import Conversation\n",
    "from ConversationScript import ConversationScript\n",
    "from ConversationScriptStage import ConversationScriptStage\n",
    "from show_chat_log import show_chat_log\n",
    "from is_question import is_question\n",
    "from customer_profile import customer_profile\n",
    "\n",
    "times_embedding_run = 10\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "RESET = \"\\033[0m\"\n",
    "BOLD = \"\\033[1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(openai_api_key=key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Embeddings generated into policies variable'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in the policies to the vectorstore\n",
    "situation_loaders = []\n",
    "situation_docs = []\n",
    "\n",
    "#create a list with the names of the files to be loaded in the data/policies folder\n",
    "for file in os.listdir('data/situational-experience'):\n",
    "    if file.endswith('.txt'):\n",
    "        loader = TextLoader('data/situational-experience/' + file)\n",
    "        situation_loaders.append(loader)\n",
    "\n",
    "for loader in situation_loaders:\n",
    "    situation_docs.extend(loader.load())\n",
    "\n",
    "if times_embedding_run < 20:\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "    documents = text_splitter.split_documents(situation_docs)\n",
    "\n",
    "    siutation_embeddings = OpenAIEmbeddings(openai_api_key=key)\n",
    "    situational_experience = Chroma.from_documents(documents, siutation_embeddings)\n",
    "    times_embedding_run += 1\n",
    "\n",
    "\n",
    "\"Embeddings generated into policies variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    }
   ],
   "source": [
    "#iterate over the contents of data/services and load them into the vectorstore\n",
    "service_loaders = []\n",
    "service_docs = []\n",
    "\n",
    "#create a list with the names of the files to be loaded in the data/services folder\n",
    "for file in os.listdir('data/services'):\n",
    "    if file.endswith('.json'):\n",
    "        loader = TextLoader('data/services/' + file)\n",
    "        service_loaders.append(loader)\n",
    "\n",
    "for loader in service_loaders:\n",
    "    service_docs.extend(loader.load())\n",
    "\n",
    "service_embeddings = OpenAIEmbeddings(openai_api_key=key)\n",
    "service_description_search = Chroma.from_documents(service_docs, service_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_services_df = pd.read_csv('data/services_search - Sheet1.csv')\n",
    "\n",
    "class Programs:\n",
    "    def __init__(self, services):\n",
    "        self.services = services\n",
    "\n",
    "    def get_service(self, name):\n",
    "        for service in self.services:\n",
    "            if service['Name'] == name:\n",
    "                return service\n",
    "        return None\n",
    "    \n",
    "class Program:\n",
    "    def __init__(self, dict):\n",
    "        self.dict = dict\n",
    "\n",
    "#create a list of dicts out of the contents of all_services_df\n",
    "all_services = []\n",
    "for index, row in all_services_df.iterrows():\n",
    "    all_services.append(row.to_dict())\n",
    "\n",
    "all_services_list = Programs(all_services)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CHAIN**: Retrieve relevant experiences from the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_situational_awareness(inputs: dict) -> dict:\n",
    "    print(GREEN + 'STEP: Getting situational experiences' + RESET)\n",
    "    customer_issue = inputs[\"customer_issue\"]\n",
    "    knowledge = situational_experience.similarity_search(customer_issue, 5)\n",
    "    knowledge = [message.page_content for message in knowledge]\n",
    "    print(RED + 'Situational experiences found: ', knowledge, RESET) \n",
    "    print(GREEN + 'STEP: Analyzing situational experiences' + RESET)       \n",
    "    return { \"situational_experience\": knowledge }\n",
    "\n",
    "retrieve_situational_awareness = TransformChain(transform=get_situational_awareness, input_variables=[\"customer_issue\"], output_variables=[\"situational_experience\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CHAIN**: Analyze the experiences we've had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_message = \"\"\"Your goal is to identify how severe this issue is. Think step by step about your answer and use the information you provided to make you answer. After your analysis, please rate the severity as Low, Medium or High.\n",
    "Customer Issue: {customer_issue}\n",
    "Property Type: {property_type}\n",
    "Below are some possible practical experiences from our technicians that may be useful. Some of it may not be relevant to your answer.\n",
    "{situational_experience}\n",
    "----\n",
    "Your Analysis:\n",
    "\"\"\"\n",
    "\n",
    "template = PromptTemplate(template=template_message, input_variables=[\"customer_issue\", \"situational_experience\", \"property_type\"])\n",
    "analyze_issue_chain = LLMChain(llm=chat, prompt=template, output_key=\"siutation_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_services(inputs: dict) -> dict:\n",
    "    analysis = inputs[\"siutation_analysis\"]\n",
    "    print(GREEN + 'STEP: Getting relevant services' + RESET)\n",
    "    service_search_results = service_description_search.similarity_search(analysis, 3)\n",
    "    #extract the services as a dict from the search results (they are json stored in .page_content)\n",
    "    service_search_results = [json.loads(result.page_content) for result in service_search_results]\n",
    "    detailed_services = []\n",
    "    for service in service_search_results:\n",
    "        service_name = service['Name']\n",
    "        detailed_service = all_services_list.get_service(service_name)\n",
    "        detailed_services.append(Program(detailed_service))\n",
    "\n",
    "    relevant_services_text = \"\"\n",
    "    for service in detailed_services:\n",
    "        relevant_services_text += service.dict['Name'] + \": \"\n",
    "        relevant_services_text += service.dict['Description'] + \"\\n\"\n",
    "        relevant_services_text += \"Best for: \" + service.dict['Best for'] + \"\\n\"\n",
    "        relevant_services_text += \"Covers: \" + service.dict['Covered Pests'] + \"\\n\"\n",
    "        relevant_services_text += \"Protection: \" + service.dict['Level of Protection'] + \"\\n\"\n",
    "        relevant_services_text += \"Price: \" + service.dict['Cost'] + \"\\n\\n\"\n",
    "    \n",
    "    print(RED + 'STEP: Completed getting services: ', detailed_services, RESET)\n",
    "    print(GREEN + 'STEP: Begin parsing the formulas' + RESET)\n",
    "\n",
    "    for service in detailed_services:\n",
    "        recurring_formula = service.dict['Recurring Formula']\n",
    "        recurring_formula = recurring_formula.replace(\"{square_footage}\", str(inputs[\"square_footage\"]))\n",
    "        recurring_formula = recurring_formula.replace(\"{target}\", str(inputs[\"target\"]))\n",
    "        recurring_formula = recurring_formula.replace(\"{severity}\", str(inputs[\"severity\"]))\n",
    "        recurring_formula = recurring_formula.replace(\"{acres}\", str(inputs[\"acres\"]))\n",
    "        service.dict['Recurring Formula'] = recurring_formula\n",
    "\n",
    "        initial_formula = service.dict['Initial Formula']\n",
    "        initial_formula = initial_formula.replace(\"{square_footage}\", str(inputs[\"square_footage\"]))\n",
    "        initial_formula = initial_formula.replace(\"{target}\", str(inputs[\"target\"]))\n",
    "        initial_formula = initial_formula.replace(\"{severity}\", str(inputs[\"severity\"]))\n",
    "        initial_formula = initial_formula.replace(\"{acres}\", str(inputs[\"acres\"]))\n",
    "        service.dict['Initial Formula'] = initial_formula\n",
    "    \n",
    "    print(GREEN + 'STEP: Completed parsing the formulas' + RESET)\n",
    "\n",
    "    return { \"relevant_services_dict\": detailed_services, \"relevant_services_text\": relevant_services_text }\n",
    "\n",
    "get_relevant_services_chain = TransformChain(transform=get_relevant_services, input_variables=[\"siutation_analysis\"], output_variables=[\"relevant_services_dict\", \"relevant_services_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "calculator_template = \"\"\"Solve this excel formula. Briefly show your thinking for each step. Then write the answer as:\n",
    "Answer: *answer*\n",
    "Example:\n",
    "=if(1=2, 1, 2) + 1\n",
    "Thinking: 1=2 is false so the answer is 2 + 1\n",
    "Answer: 3\n",
    "Formula:\n",
    "{formula}\n",
    "\"\"\"\n",
    "\n",
    "#majority vote will take in a list of results and return the most common answer for each type and name (ex. item: {'name': 'Service 1', 'answer': '5', 'type': 'recurring', 'iter_num': 0})\n",
    "def majority_vote(results):\n",
    "    # Group by name and type\n",
    "    grouped_results = {}\n",
    "    for result in results:\n",
    "        name = result['name']\n",
    "        type = result['type']\n",
    "        if name not in grouped_results:\n",
    "            grouped_results[name] = {}\n",
    "        if type not in grouped_results[name]:\n",
    "            grouped_results[name][type] = []\n",
    "        grouped_results[name][type].append(result)\n",
    "\n",
    "    # Find the most common answer for each name and type, excluding None unless it's the only result\n",
    "    majority_vote_results = []\n",
    "    for name in grouped_results:\n",
    "        for type in grouped_results[name]:\n",
    "            answers = [result['answer'] for result in grouped_results[name][type]]\n",
    "            \n",
    "            # Exclude None values if there are other non-None values\n",
    "            non_none_answers = [answer for answer in answers if answer is not None]\n",
    "            if non_none_answers:\n",
    "                answers = non_none_answers\n",
    "\n",
    "            answer = max(set(answers), key=answers.count)\n",
    "            majority_vote_results.append({'name': name, 'answer': answer, 'type': type})\n",
    "\n",
    "    return majority_vote_results\n",
    "\n",
    "\n",
    "async def async_calculate_price(name, chain, formula, type, iter=1, timeout=8):\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "    answer = None\n",
    "    \n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            resp = await asyncio.wait_for(chain.arun(formula=formula), timeout=timeout)\n",
    "            print(BOLD, resp, RESET)\n",
    "            # parse the Answer: *answer* from the response using regex\n",
    "            answer = re.search(r'Answer:\\s*\\$?(\\d+(?:\\.\\d+)?)\\s*[^\\d\\(\\)]*', resp)\n",
    "            \n",
    "            #if there is a match, break the loop\n",
    "            if answer is not None:\n",
    "                answer = answer.group(1)\n",
    "                break\n",
    "        except asyncio.TimeoutError:\n",
    "            print(RED + f\"STEP: Timeout reached for {formula} after {timeout} seconds (Retry {retries + 1})\" + RESET)\n",
    "            retries += 1\n",
    "    \n",
    "    if answer is None:\n",
    "        print(RED + f\"STEP: Failed to parse answer from response after {max_retries} retries\" + RESET)\n",
    "    \n",
    "    return { \"name\": name, \"answer\": answer, \"type\": type, \"iter_num\": iter }\n",
    "\n",
    "async def get_pricing(inputs: dict) -> dict:\n",
    "    print(GREEN + 'STEP: Generating recurring price' + RESET)\n",
    "    services = inputs[\"relevant_services_dict\"]\n",
    "    tasks = []\n",
    "    for service in services:\n",
    "        name = service.dict['Name']\n",
    "        recurring_formula = service.dict['Recurring Formula']\n",
    "        intial_formula = service.dict['Initial Formula']\n",
    "        calculator_prompt = PromptTemplate(\n",
    "            template=calculator_template,\n",
    "            input_variables=[\"formula\"]\n",
    "        )\n",
    "        chain = LLMChain(llm=chat, prompt=calculator_prompt, output_key=\"recurring_logic\")\n",
    "        #majority vote\n",
    "        for n in range(1, 3):\n",
    "            recurring_task = asyncio.create_task(async_calculate_price(name, chain, recurring_formula, 'recurring', iter=n))\n",
    "            initial_task = asyncio.create_task(async_calculate_price(name, chain, intial_formula, 'initial', iter=n))\n",
    "            tasks.append(recurring_task)\n",
    "            tasks.append(initial_task)\n",
    "\n",
    "    print(GREEN + 'All Tasks Added to Queue' + RESET)\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(GREEN, 'All Tasks Completed' + RESET)\n",
    "    print(GREEN, 'Holding majority vote' + RESET)\n",
    "    results = majority_vote(results)\n",
    "    print(GREEN, 'Majority vote complete' + RESET)\n",
    "\n",
    "    for service in services:\n",
    "        name = service.dict['Name']\n",
    "        for result in results:\n",
    "            if name == result['name'] and result['type'] == 'recurring':\n",
    "                service.dict['Recurring Price'] = result['answer']\n",
    "            if name == result['name'] and result['type'] == 'initial':\n",
    "                service.dict['Initial Price'] = result['answer']\n",
    "    \n",
    "    service_offers_formatted = \"\"\n",
    "    for service in services:\n",
    "        service_offers_formatted += service.dict['Outward Facing'] + '\\n'\n",
    "        service_offers_formatted += 'Initial Price: $' + service.dict['Initial Price'] + '\\n'\n",
    "        service_offers_formatted += 'Recurring Price: $' + service.dict['Recurring Price'] + '\\n'\n",
    "        service_offers_formatted += 'Description: ' + service.dict['Description'] + '\\n'\n",
    "        service_offers_formatted += 'Covered Pests: ' + service.dict['Covered Pests'] + '\\n'\n",
    "        service_offers_formatted += 'Best For: ' + service.dict['Best for'] + '\\n'\n",
    "        service_offers_formatted += 'Frequency: ' + service.dict['Frequency'] + '\\n'\n",
    "        service_offers_formatted += 'Level of Protection: ' + service.dict['Level of Protection'] + '\\n'\n",
    "        service_offers_formatted += 'Benefits: ' + service.dict['Benefits'] + '\\n'\n",
    "        service_offers_formatted += 'Payment Link: <pay:' + service.dict['Name'] + '>\\n'\n",
    "        service_offers_formatted += '\\n'\n",
    "\n",
    "    return { \"complete_services\": services, \"service_offers_formatted\": service_offers_formatted }\n",
    "\n",
    "def add_prices(inputs):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    nest_asyncio.apply(loop)\n",
    "    response = loop.run_until_complete(get_pricing(inputs))\n",
    "    return { \"complete_services\": response[\"complete_services\"], \"service_offers_formatted\": response['service_offers_formatted'] }\n",
    "\n",
    "\n",
    "calculate_prices_chain = TransformChain(\n",
    "    transform=add_prices, \n",
    "    input_variables=[\"relevant_services_dict\"], \n",
    "    output_variables=[\"complete_services\", \"service_offers_formatted\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_template = \"\"\"You are an expert and friendly salesperson for a sales company. You have just finished collecting information from the customer. Provide a helpful and entertaining explaination of the best service you found for them based on the following service and issue. Focus on service benefits and avoid being overly technical. Be casual and pretend you are chatting with a friend. At the end include the payment link. \n",
    "Customer Issue: {customer_issue}\n",
    "Customer Preferences: {customer_preferences}\n",
    "Your Analysis: {siutation_analysis}\n",
    "Conversation So Far: \n",
    "{conversation_history}\n",
    "Services you can choose from: \n",
    "{service_offers_formatted}\n",
    "Your pitch:\n",
    "\"\"\"\n",
    "\n",
    "parser_prompt = PromptTemplate(template=pitch_template, input_variables=[\"conversation_history\", \"customer_issue\", \"customer_preferences\", \"service_offers_formatted\", \"siutation_analysis\"])\n",
    "sales_pitch_chain = LLMChain(llm=chat, prompt=parser_prompt, output_key=\"pitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Payments:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "    \n",
    "    def create_payment_link(self, service_id, initial):\n",
    "        stripe.api_key = self.api_key\n",
    "        unit_amount = int(initial * 100)\n",
    "        #create the price for the service in the stripe dashboard\n",
    "        price = stripe.Price.create(currency=\"usd\", unit_amount=unit_amount, product=service_id)\n",
    "        price_id = price.id\n",
    "        #create the payment link\n",
    "        link = stripe.checkout.Session.create(\n",
    "            payment_method_types=['card'],\n",
    "            line_items=[\n",
    "                {\n",
    "                    'price': price_id,\n",
    "                    'quantity': 1,\n",
    "                },\n",
    "            ],\n",
    "            mode='payment',\n",
    "            success_url='https://example.com/success',\n",
    "            cancel_url='https://example.com/cancel',\n",
    "        )\n",
    "        return link.url\n",
    "\n",
    "\n",
    "pay = Payments(api_key=os.getenv('STRIPE_KEY'))\n",
    "\n",
    "def add_payment_links(inputs):\n",
    "    services = inputs[\"complete_services\"]\n",
    "    updated_services = []\n",
    "    for service in services:\n",
    "        service_id = service.dict['Service ID']\n",
    "        initial = float(service.dict['Initial Price'])\n",
    "        if initial == 0:\n",
    "            initial = float(service.dict['Recurring Price'])\n",
    "        link = pay.create_payment_link(service_id, initial)\n",
    "        service.dict['Payment Link'] = link\n",
    "        updated_services.append(service)\n",
    "\n",
    "    return { \"complete_services_with_links\": updated_services }\n",
    "\n",
    "payment_links_chain = TransformChain(\n",
    "    transform=add_payment_links,\n",
    "    input_variables=[\"complete_services\"],\n",
    "    output_variables=[\"complete_services_with_links\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pitch(inputs):\n",
    "    pitch = inputs[\"pitch\"]\n",
    "    #find the string in the form of <pay:service_name>\n",
    "    payment_link = re.search(r'<pay:(.*?)>', pitch)\n",
    "    if payment_link:\n",
    "        print(GREEN, 'Found payment link' + RESET)\n",
    "        program_name = payment_link.group(1).strip()\n",
    "    else:\n",
    "        print(RED, 'No payment link found' + RESET)\n",
    "        program_name = ''\n",
    "    #find the service that matches the name\n",
    "    services = inputs[\"complete_services_with_links\"]\n",
    "    payment_link = \"http://error.com\"\n",
    "    for service in services:\n",
    "        if service.dict['Name'] == program_name:\n",
    "            payment_link = service.dict['Payment Link']\n",
    "    \n",
    "    #replace the string with the payment link\n",
    "    pitch = re.sub(r'<pay:(.*?)>', payment_link, pitch)\n",
    "    return { \"final pitch\": pitch }\n",
    "\n",
    "parse_pitch_chain = TransformChain(\n",
    "    transform=parse_pitch,\n",
    "    input_variables=[\"pitch\", \"complete_services\"],\n",
    "    output_variables=[\"final pitch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "analyze_situation_sequential = SequentialChain(\n",
    "    chains=[\n",
    "        retrieve_situational_awareness,\n",
    "        analyze_issue_chain,\n",
    "        get_relevant_services_chain,\n",
    "        calculate_prices_chain,\n",
    "        payment_links_chain,\n",
    "        sales_pitch_chain,\n",
    "        parse_pitch_chain\n",
    "    ],\n",
    "    input_variables=[\"customer_issue\", \"customer_preferences\", \"square_footage\", \"property_type\", \"acres\", \"target\", \"severity\", \"conversation_history\"],\n",
    "    output_variables=[\n",
    "        \"situational_experience\", \n",
    "        \"siutation_analysis\", \n",
    "        \"relevant_services_dict\",\n",
    "        \"complete_services\",\n",
    "        \"service_offers_formatted\",\n",
    "        \"pitch\",\n",
    "        \"final pitch\"\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"\"\"\n",
    "Lead: I have a problem with ants in my kitchen.\n",
    "Agent: Oh no! I'm sorry to hear that John. Luckily we can help with that :) Would you mind if I asked you a few questions so I can get a handle on your issue?\n",
    "Lead: Sure, go ahead.\n",
    "Agent: Great thanks! First how long has this been going on?\n",
    "Lead: 2 Weeks\n",
    "Agent: And how many ants are you seeing?\n",
    "Lead: A lot! They are all over the kitchen.\n",
    "Agent: OK don't worry I see this kind of thing all the time. How big is your house?\n",
    "Lead: 2000 square feet\n",
    "Agent: Got it. Give me just a second and let me run some numbers for you.\n",
    "Agent: OK here's what I'm thinking:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\u001b[92mSTEP: Getting situational experiences\u001b[0m\n",
      "\u001b[91mSituational experiences found:  ['Carpenter ants are usually harder to control than ants and will require bimonthly or monthly services.', 'Ants can be well managed by bimonthly service frequencies. It is less advisable, but still an option to allow customers to use quarterly services. Monthly services are often overkill for ant issues.', 'Program 1 for termites does not work well in townhouses or apartments'] \u001b[0m\n",
      "\u001b[92mSTEP: Analyzing situational experiences\u001b[0m\n",
      "\u001b[92mSTEP: Getting relevant services\u001b[0m\n",
      "\u001b[91mSTEP: Completed getting services:  [<__main__.Program object at 0x14cf06310>, <__main__.Program object at 0x16808c1f0>, <__main__.Program object at 0x1680124c0>] \u001b[0m\n",
      "\u001b[92mSTEP: Begin parsing the formulas\u001b[0m\n",
      "\u001b[92mSTEP: Completed parsing the formulas\u001b[0m\n",
      "\u001b[92mSTEP: Generating recurring price\u001b[0m\n",
      "\u001b[92mAll Tasks Added to Queue\u001b[0m\n",
      "\u001b[1m Thinking: The first condition, \"medium\"=\"high\", is false so it moves to the nested if statement. The second condition, \"medium\"=\"medium\" is true, so the result is 149. \n",
      "\n",
      "Answer: 149 \u001b[0m\n",
      "\u001b[1m Thinking: The formula checks if \"medium\" is equal to \"high\". Since it's not, it moves to the next argument which checks if \"medium\" is equal to \"medium\". Since it is, the result is 149. \n",
      "Answer: 149 \u001b[0m\n",
      "\u001b[1m Thinking: \n",
      "- 2500 divided by 5 is 500. Adding 1200 to it gives us 1700.\n",
      "- The second part of the formula is an IF statement. If \"medium\" equals high, then the answer would be 300. Otherwise, the answer would be 0.\n",
      "\n",
      "Answer: 2000 \u001b[0m\n",
      "\u001b[1m Thinking: The switch function is checking for the keyword \"millipede\" and returning the value 75. The if function is checking if 2500 is greater than or equal to both 4000 and 2500. Since neither are true, it will return 5. Finally, we are adding 50 to the sum of these two values.\n",
      "Answer: 130 \u001b[0m\n",
      "\u001b[1m Thinking: \n",
      "- 2500 divided by 5 equals 500 and then we add 1200 to get 1700. \n",
      "- The if statement evaluates whether \"medium\" is equal to \"high\". Since they are not equal, the result will be 0. \n",
      "- Therefore, the answer is 1700 + 0 = 1700.\n",
      "\n",
      "Answer: 1700 \u001b[0m\n",
      "\u001b[1m Thinking: First, we check if \"medium\" is equal to \"high\", which is false. Therefore, we move on to the next argument of the IF statement, which is another IF statement. This time, we check if \"medium\" is equal to \"medium\", which is true. Therefore, the answer is 149, as per the second argument of the inner IF statement.\n",
      "\n",
      "Answer: 149 \u001b[0m\n",
      "\u001b[1m Thinking: The switch function is evaluating the word \"millipede\" and returning the number 75. The if function is evaluating if 2500 is greater or equal to 4000, which is false, so it moves to the next argument, which is evaluating if 2500 is greater or equal to 2500, which is true, so it returns 5. Therefore, the final answer is 75 + 5 = 80.\n",
      "Answer: 80 \u001b[0m\n",
      "\u001b[1m Thinking: The formula checks if \"medium\" is equal to \"high\". Since they are not equal, it moves on to the second argument which is another \"if\" statement. This statement checks if the value of \"medium\" is equal to \"medium\". If it is, the formula returns 149. If it's not, the last argument returns 0.\n",
      "Answer: 0 (Assuming \"medium\" is not defined as a named range or a cell reference) \u001b[0m\n",
      "\u001b[1m Thinking: The formula contains a switch function where it will check the value \"millipede\" and will return 75. The value of the function is then added with another function. The second function checks if 2500 is greater than or equal to 4000 which is false. Therefore the function moves to the next if statement where it checks whether 2500 is greater than or equal to 2500, which is true. The output for true is 5, so the resulting value will be 75 + 5.\n",
      "Answer: 80 \u001b[0m\n",
      "\u001b[1m Thinking: \n",
      "\n",
      "The first part of the formula uses the SWITCH function to check which category \"millipede\" belongs to and returns the corresponding value. Since \"millipedes\" is listed with a value of 75, this part of the formula will evaluate to 75.\n",
      "\n",
      "The second part of the formula uses an IF function to check if 2500 is greater than or equal to 4000. This is false, so it moves on to the next conditional which checks if 2500 is greater than or equal to 2500. This is true, so the value returned will be 5.\n",
      "\n",
      "Finally, the last part of the formula adds 50 to the result of the previous two calculations.\n",
      "\n",
      "Answer: 130 \u001b[0m\n",
      "\u001b[1m Thinking: \n",
      "\n",
      "First, we are using the switch function to find the score associated with the word \"millipede\". The score for \"millipede\" is 75, as given in the second argument of the switch function.\n",
      "\n",
      "Next, we are adding to that score an if function with two conditions. The first condition is false (2500 is not greater than or equal to 4000), so we move on to the second condition. The second condition is true (2500 is greater than or equal to 2500) so the answer to the if function is 10.\n",
      "\n",
      "Finally, we add the score from the switch function (75) to the answer from the if function (10).\n",
      "\n",
      "Answer: 85 \u001b[0m\n",
      "\u001b[91mSTEP: Timeout reached for switch(\"millipede\", \"ants\", 75, \"spiders\", 75, \"roaches\", 90, \"rats\", 85, \"mice\", 85, \"millipedes\", 75, \"centipedes\", 75,  80) + if(2500 >= 4000, 15, if(2500 >= 2500, 10, 5)) after 8 seconds (Retry 1)\u001b[0m\n",
      "\u001b[1m Thinking: \n",
      "1. The switch function checks for the value \"millipede\" and returns 75, since that is the corresponding value in the formula.\n",
      "2. The if statement checks if 2500 is greater than or equal to 4000, which is false. So, it moves on to the nested if statement.\n",
      "3. The nested if statement checks if 2500 is greater than or equal to 2500, which is true. So, it returns 10.\n",
      "4. Finally, it adds 75 (from the switch function) and 10 (from the if statement) to get the answer.\n",
      "\n",
      "Answer: 85 \u001b[0m\n",
      "\u001b[92m All Tasks Completed\u001b[0m\n",
      "\u001b[92m Holding majority vote\u001b[0m\n",
      "\u001b[92m Majority vote complete\u001b[0m\n",
      "\u001b[92m Found payment link\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = analyze_situation_sequential({\n",
    "    \"customer_issue\": \"ants in kitchen\",\n",
    "    \"customer_preferences\": \"none stated\",\n",
    "    \"property_type\": \"single family\",\n",
    "    \"square_footage\": 2500,\n",
    "    \"acres\": 1,\n",
    "    \"target\": \"ants\",\n",
    "    \"severity\": \"high\",\n",
    "    \"conversation_history\": conversation\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey John, based on our conversation, I think the Castle Program would be the best service for you to handle those pesky ants in your kitchen. The service offers bimonthly pest control to cover the ant issue, as well as millipedes, crickets, and centipedes. With this program, you'll have proactive annual termite inspections to help reduce the risk of undetected termites in your home. Plus, you'll get year-round protection against 33 pests, with a level of protection that's average, but still more than enough for your current issue. And the best part? You'll have the convenience of a single bill on autopilot. \n",
      "\n",
      "I hope this helps, John! We take pride in offering affordable and effective pest control services to our customers, and I'm confident that the Castle Program will take care of all your ant troubles. Let me send you the payment link right here: https://checkout.stripe.com/c/pay/cs_test_a1PytlOBsB3AyUqNOOaNI7EakaWfzai5EW0iGT1zMUaqilmOssAilJ9jYY#fidkdWxOYHwnPyd1blpxYHZxWjA0TTJoRHZOaGtxTUlPdF9PR1VGYGdOXHMwVU4zNFVkXERqbWlITX82VHdmaVxtXFZSYHdOaGZTa0RUa1Y0ZEpjVF9CVV9KYzBnTEB9a1cxUmc0TGNwZEwyNTU2UTVmc1JgZicpJ2N3amhWYHdzYHcnP3F3cGApJ2lkfGpwcVF8dWAnPyd2bGtiaWBabHFgaCcpJ2BrZGdpYFVpZGZgbWppYWB3dic%2FcXdwYHgl\n"
     ]
    }
   ],
   "source": [
    "print(response['final pitch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['customer_issue',\n",
    " 'customer_preferences',\n",
    " 'property_type',\n",
    " 'square_footage',\n",
    " 'acres',\n",
    " 'target',\n",
    " 'severity',\n",
    " 'situational_experience',\n",
    " 'siutation_analysis',\n",
    " 'service_search_term',\n",
    " 'services_plain_text',\n",
    " 'thinking_through_service_rankings',\n",
    " 'service_id_list',\n",
    " 'service_ids',\n",
    " 'offers',\n",
    " 'recurring_formula_parsed',\n",
    " 'initial_formula_parsed',\n",
    " 'recurring_logic',\n",
    " 'initial_logic',\n",
    " 'recurring_price',\n",
    " 'initial_price',\n",
    " 'pitch']\n",
    "\n",
    "def observe_steps(steps, start, num_steps):\n",
    "    step_list = [\n",
    "        f'Inputs: Customer Issues: {steps[\"customer_issue\"]}\\nCustomer Preferences: {steps[\"customer_preferences\"]}\\nProperty Type: {steps[\"property_type\"]}\\nSquare Footage: {steps[\"square_footage\"]}\\nAcres: {steps[\"acres\"]}\\nTarget: {steps[\"target\"]}\\nSeverity: {steps[\"severity\"]}',\n",
    "        f'situational_experience: {steps[\"situational_experience\"]}',\n",
    "        f'siutation_analysis: {steps[\"siutation_analysis\"]}',\n",
    "        f'service_search_term: {steps[\"service_search_term\"]}',\n",
    "        f'services_plain_text: {steps[\"services_plain_text\"]}',\n",
    "        f'thinking_through_service_rankings: {steps[\"thinking_through_service_rankings\"]}',\n",
    "        f'service_id_list: {steps[\"service_id_list\"]}',\n",
    "        f'service_ids: {steps[\"service_ids\"]}',\n",
    "        f'offers: {steps[\"offers\"]}',\n",
    "        f'recurring_formula_parsed: {steps[\"recurring_formula_parsed\"]}',\n",
    "        f'recurring_logic: {steps[\"recurring_logic\"]}',\n",
    "        f'recurring_price: {steps[\"recurring_price\"]}',\n",
    "        f'initial_formula_parsed: {steps[\"initial_formula_parsed\"]}',\n",
    "        f'initial_logic: {steps[\"initial_logic\"]}',\n",
    "        f'initial_price: {steps[\"initial_price\"]}',\n",
    "        f'pitch: {steps[\"pitch\"]}'\n",
    "    ]\n",
    "\n",
    "    end = start + num_steps\n",
    "    list = step_list[start:end]\n",
    "    for i in list:\n",
    "        print(i)\n",
    "        print('-----------------')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec0f111f5e5040c678ec5a567f7682a80a3d7b8519cf7f13b3475890ed8a264f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
