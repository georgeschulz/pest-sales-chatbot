{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import sys\n",
    "pd.options.mode.chained_assignment = None\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain import PromptTemplate, LLMChain, VectorDBQA\n",
    "from langchain.chains import TransformChain, SequentialChain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "import re\n",
    "import json\n",
    "import stripe\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "import asyncio\n",
    "\n",
    "from langchain.chains import APIChain\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules/')\n",
    "openai.api_key = os.getenv('OPENAI_KEY')\n",
    "key = os.getenv('OPENAI_KEY')\n",
    "\n",
    "from Generator import Generator\n",
    "from Extractor import Extractor\n",
    "from PromptPath import PromptPath\n",
    "from GenExtract import GenExtract\n",
    "from Property import Property\n",
    "from NaturalLanguagePool import NaturalLanguagePool\n",
    "from DynamicChatHistory import DynamicChatHistory\n",
    "from Conversation import Conversation\n",
    "from ConversationScript import ConversationScript\n",
    "from ConversationScriptStage import ConversationScriptStage\n",
    "from show_chat_log import show_chat_log\n",
    "from is_question import is_question\n",
    "from customer_profile import customer_profile\n",
    "\n",
    "times_embedding_run = 10\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "GREEN = \"\\033[92m\"\n",
    "RESET = \"\\033[0m\"\n",
    "BOLD = \"\\033[1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(openai_api_key=key)\n",
    "gpt4 = ChatOpenAI(openai_api_key=key, model_name=\"gpt-4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "loaded in 78 embeddings\n",
      "loaded in 1 collections\n",
      "collection with name langchain already exists, returning existing collection\n",
      "Persisting DB to disk, putting it in the save folder data/situation-db/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Embeddings generated into policies variable'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in the policies to the vectorstore\n",
    "situation_loaders = []\n",
    "situation_docs = []\n",
    "\n",
    "#create a list with the names of the files to be loaded in the data/policies folder\n",
    "for file in os.listdir('data/situational-experience'):\n",
    "    if file.endswith('.txt'):\n",
    "        loader = TextLoader('data/situational-experience/' + file)\n",
    "        situation_loaders.append(loader)\n",
    "\n",
    "for loader in situation_loaders:\n",
    "    situation_docs.extend(loader.load())\n",
    "\n",
    "if times_embedding_run < 20:\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "    documents = text_splitter.split_documents(situation_docs)\n",
    "\n",
    "    siutation_embeddings = OpenAIEmbeddings(openai_api_key=key)\n",
    "    situational_experience = Chroma.from_documents(documents, siutation_embeddings, persist_directory='data/situation-db/')\n",
    "    situational_experience.persist()\n",
    "    times_embedding_run += 1\n",
    "\n",
    "\n",
    "\"Embeddings generated into policies variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "No existing DB found in data/services-db/, skipping load\n",
      "No existing DB found in data/services-db/, skipping load\n"
     ]
    }
   ],
   "source": [
    "#iterate over the contents of data/services and load them into the vectorstore\n",
    "service_loaders = []\n",
    "service_docs = []\n",
    "\n",
    "#create a list with the names of the files to be loaded in the data/services folder\n",
    "for file in os.listdir('data/services'):\n",
    "    if file.endswith('.json'):\n",
    "        loader = TextLoader('data/services/' + file)\n",
    "        service_loaders.append(loader)\n",
    "\n",
    "for loader in service_loaders:\n",
    "    service_docs.extend(loader.load())\n",
    "\n",
    "service_embeddings = OpenAIEmbeddings(openai_api_key=key)\n",
    "service_description_search = Chroma.from_documents(service_docs, service_embeddings, persist_directory='data/services-db/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\"Based on the conversation, the customer is experiencing mosquito activity throughout their 2.5 acre, 3000 square foot single-family townhome property. The agent also asks about other pests, implying that the focus here is on mosquito control. The practical experiences mentioned suggest that factors like yard wetness, shade, and vegetation will affect the effectiveness of treatment and pricing. \\n\\nOverall, this issue seems to be of Medium severity. While the customer is experiencing a problem with mosquitos, it is not a life-threatening or urgent issue. However, it is impacting their ability to enjoy their yard and may be a nuisance. Additionally, the size of the property may require a more specific treatment plan and could result in higher prices.\"\"\"\n",
    "\n",
    "resp = service_description_search.similarity_search(query, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program 6\n",
      "Program 4\n",
      "Program 5\n",
      "\n",
      "total:  3\n"
     ]
    }
   ],
   "source": [
    "clean = [json.loads(result.page_content) for result in resp]\n",
    "for item in clean:\n",
    "    print(item['Name'])\n",
    "print('\\ntotal: ', len(clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_services_df = pd.read_csv('data/services_search - Sheet1.csv')\n",
    "\n",
    "class Programs:\n",
    "    def __init__(self, services):\n",
    "        self.services = services\n",
    "\n",
    "    def get_service(self, name):\n",
    "        for service in self.services:\n",
    "            if service['Name'] == name:\n",
    "                return service\n",
    "        return None\n",
    "    \n",
    "class Program:\n",
    "    def __init__(self, dict):\n",
    "        self.dict = dict\n",
    "\n",
    "#create a list of dicts out of the contents of all_services_df\n",
    "all_services = []\n",
    "for index, row in all_services_df.iterrows():\n",
    "    all_services.append(row.to_dict())\n",
    "\n",
    "all_services_list = Programs(all_services)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CHAIN**: Retrieve relevant experiences from the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_situational_awareness(inputs: dict) -> dict:\n",
    "    print(GREEN + 'STEP: Getting situational experiences' + RESET)\n",
    "    conversastion = inputs[\"conversation_history\"]\n",
    "    knowledge = situational_experience.similarity_search(conversastion, 5)\n",
    "    knowledge = [message.page_content for message in knowledge]\n",
    "    print(RED + 'Situational experiences found: ', knowledge, RESET) \n",
    "    print(GREEN + 'STEP: Analyzing situational experiences' + RESET)       \n",
    "    return { \"situational_experience\": knowledge }\n",
    "\n",
    "retrieve_situational_awareness = TransformChain(transform=get_situational_awareness, input_variables=[\"conversation_history\"], output_variables=[\"situational_experience\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CHAIN**: Analyze the experiences we've had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_message = \"\"\"Your goal is to identify how severe this issue is. Think step by step about your answer and use the information you provided to make you answer. After your analysis, please rate the severity as Low, Medium or High.\n",
    "Conversation so Far: \n",
    "{conversation_history}\n",
    "Property Type: {property_type}\n",
    "Below are some possible practical experiences from our technicians that may be useful. Some of it may not be relevant to your answer.\n",
    "{situational_experience}\n",
    "----\n",
    "Your Analysis:\n",
    "\"\"\"\n",
    "\n",
    "template = PromptTemplate(template=template_message, input_variables=[\"situational_experience\", \"property_type\", \"conversation_history\"])\n",
    "analyze_issue_chain = LLMChain(llm=chat, prompt=template, output_key=\"siutation_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_grade_template = \"\"\"Provide a rating for the severity of the issue. Please rate the severity as \"Low\", \"Medium\" or \"High\".\n",
    "Issue Analysis: {situation_analysis}\"\"\"\n",
    "\n",
    "severity_grade_prompt = PromptTemplate(template=severity_grade_template, input_variables=[\"situation_analysis\"])\n",
    "\n",
    "severity_grade_chain = LLMChain(llm=gpt4, prompt=severity_grade_prompt, output_key=\"severity_grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low']\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    \"The severity of this issue is low. The user is only dealing with spiders in specific areas of their home and has provided the square footage of their property, making it easier for the agent to determine the best treatment plan. Additionally, there is no indication of any potential health or safety risks.\",\n",
    "    \"Based on the conversation, the severity of the rodent issue is high. The customer has reported seeing rodents in multiple areas of the house, including their child's room, and also mentioned that the rodents are leaving droppings all over the house. Additionally, the customer is unable to pinpoint where the rodents are entering from, indicating that the infestation may be widespread. The practical experience provided also suggests that if a customer seems dishonest or withholding information about the rodent issue, the situation is probably worse than expected. Therefore, it is recommended to have an expert technician come over for an inspection to address the problem promptly.\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1):\n",
    "    response = severity_grade_chain({ \"situation_analysis\": tests[0] })\n",
    "    pattern = re.compile(r'(Low|Medium|High)', re.IGNORECASE)\n",
    "    matches = pattern.findall(response['severity_grade'])\n",
    "\n",
    "    if matches:\n",
    "        response = matches[-1]\n",
    "        rating = response.strip().lower()\n",
    "    else:\n",
    "        rating = None\n",
    "    \n",
    "    results.append(rating)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_services(inputs: dict) -> dict:\n",
    "    analysis = inputs[\"siutation_analysis\"]\n",
    "    print(GREEN + 'STEP: Getting relevant services' + RESET)\n",
    "    service_search_results = service_description_search.similarity_search(analysis, 3)\n",
    "    #extract the services as a dict from the search results (they are json stored in .page_content)\n",
    "    service_search_results = [json.loads(result.page_content) for result in service_search_results]\n",
    "    detailed_services = []\n",
    "    for service in service_search_results:\n",
    "        service_name = service['Name']\n",
    "        detailed_service = all_services_list.get_service(service_name)\n",
    "        detailed_services.append(Program(detailed_service))\n",
    "\n",
    "    relevant_services_text = \"\"\n",
    "    for service in detailed_services:\n",
    "        relevant_services_text += service.dict['Name'] + \": \"\n",
    "        relevant_services_text += service.dict['Description'] + \"\\n\"\n",
    "        relevant_services_text += \"Best for: \" + service.dict['Best for'] + \"\\n\"\n",
    "        relevant_services_text += \"Covers: \" + service.dict['Covered Pests'] + \"\\n\"\n",
    "        relevant_services_text += \"Protection: \" + service.dict['Level of Protection'] + \"\\n\"\n",
    "        relevant_services_text += \"Price: \" + service.dict['Cost'] + \"\\n\\n\"\n",
    "    \n",
    "    print(RED + 'STEP: Completed getting services: ', detailed_services, RESET)\n",
    "    print(GREEN + 'STEP: Begin parsing the formulas' + RESET)\n",
    "\n",
    "    for service in detailed_services:\n",
    "        recurring_formula = service.dict['Recurring Formula']\n",
    "        recurring_formula = recurring_formula.replace(\"{square_footage}\", str(inputs[\"square_footage\"]))\n",
    "        recurring_formula = recurring_formula.replace(\"{target}\", str(inputs[\"target\"]))\n",
    "        recurring_formula = recurring_formula.replace(\"{severity}\", str(inputs[\"severity\"]))\n",
    "        recurring_formula = recurring_formula.replace(\"{acres}\", str(inputs[\"acres\"]))\n",
    "        service.dict['Recurring Formula'] = recurring_formula\n",
    "\n",
    "        initial_formula = service.dict['Initial Formula']\n",
    "        initial_formula = initial_formula.replace(\"{square_footage}\", str(inputs[\"square_footage\"]))\n",
    "        initial_formula = initial_formula.replace(\"{target}\", str(inputs[\"target\"]))\n",
    "        initial_formula = initial_formula.replace(\"{severity}\", str(inputs[\"severity\"]))\n",
    "        initial_formula = initial_formula.replace(\"{acres}\", str(inputs[\"acres\"]))\n",
    "        service.dict['Initial Formula'] = initial_formula\n",
    "    \n",
    "    print(GREEN + 'STEP: Completed parsing the formulas' + RESET)\n",
    "\n",
    "    return { \"relevant_services_dict\": detailed_services, \"relevant_services_text\": relevant_services_text }\n",
    "\n",
    "get_relevant_services_chain = TransformChain(transform=get_relevant_services, input_variables=[\"siutation_analysis\"], output_variables=[\"relevant_services_dict\", \"relevant_services_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator_template = \"\"\"Solve this excel formula. Briefly show your thinking for each step. Then write the answer as:\n",
    "Answer: *answer*\n",
    "Example:\n",
    "=if(1=2, 1, 2) + 1\n",
    "Thinking: 1=2 is false so the answer is 2 + 1\n",
    "Answer: 3\n",
    "Formula:\n",
    "{formula}\n",
    "\"\"\"\n",
    "\n",
    "#majority vote will take in a list of results and return the most common answer for each type and name (ex. item: {'name': 'Service 1', 'answer': '5', 'type': 'recurring', 'iter_num': 0})\n",
    "def majority_vote(results):\n",
    "    # Group by name and type\n",
    "    grouped_results = {}\n",
    "    for result in results:\n",
    "        name = result['name']\n",
    "        type = result['type']\n",
    "        if name not in grouped_results:\n",
    "            grouped_results[name] = {}\n",
    "        if type not in grouped_results[name]:\n",
    "            grouped_results[name][type] = []\n",
    "        grouped_results[name][type].append(result)\n",
    "\n",
    "    # Find the most common answer for each name and type, excluding None unless it's the only result\n",
    "    majority_vote_results = []\n",
    "    for name in grouped_results:\n",
    "        for type in grouped_results[name]:\n",
    "            answers = [result['answer'] for result in grouped_results[name][type]]\n",
    "            \n",
    "            # Exclude None values if there are other non-None values\n",
    "            non_none_answers = [answer for answer in answers if answer is not None]\n",
    "            if non_none_answers:\n",
    "                answers = non_none_answers\n",
    "\n",
    "            answer = max(set(answers), key=answers.count)\n",
    "            majority_vote_results.append({'name': name, 'answer': answer, 'type': type})\n",
    "\n",
    "    return majority_vote_results\n",
    "\n",
    "\n",
    "async def async_calculate_price(name, chain, formula, type, iter=1, timeout=8):\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "    answer = None\n",
    "    \n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            resp = await asyncio.wait_for(chain.arun(formula=formula), timeout=timeout)\n",
    "            print(BOLD, resp, RESET)\n",
    "            # parse the Answer: *answer* from the response using regex\n",
    "            answer = re.search(r'Answer:\\s*\\$?(\\d+(?:\\.\\d+)?)\\s*[^\\d\\(\\)]*', resp)\n",
    "            \n",
    "            #if there is a match, break the loop\n",
    "            if answer is not None:\n",
    "                answer = answer.group(1)\n",
    "                break\n",
    "        except asyncio.TimeoutError:\n",
    "            print(RED + f\"STEP: Timeout reached for {formula} after {timeout} seconds (Retry {retries + 1})\" + RESET)\n",
    "            retries += 1\n",
    "    \n",
    "    if answer is None:\n",
    "        print(RED + f\"STEP: Failed to parse answer from response after {max_retries} retries\" + RESET)\n",
    "    \n",
    "    return { \"name\": name, \"answer\": answer, \"type\": type, \"iter_num\": iter }\n",
    "\n",
    "async def get_pricing(inputs: dict) -> dict:\n",
    "    print(GREEN + 'STEP: Generating recurring price' + RESET)\n",
    "    services = inputs[\"relevant_services_dict\"]\n",
    "    tasks = []\n",
    "    for service in services:\n",
    "        name = service.dict['Name']\n",
    "        recurring_formula = service.dict['Recurring Formula']\n",
    "        intial_formula = service.dict['Initial Formula']\n",
    "        calculator_prompt = PromptTemplate(\n",
    "            template=calculator_template,\n",
    "            input_variables=[\"formula\"]\n",
    "        )\n",
    "        chain = LLMChain(llm=chat, prompt=calculator_prompt, output_key=\"recurring_logic\")\n",
    "        #majority vote\n",
    "        for n in range(1, 3):\n",
    "            recurring_task = asyncio.create_task(async_calculate_price(name, chain, recurring_formula, 'recurring', iter=n))\n",
    "            initial_task = asyncio.create_task(async_calculate_price(name, chain, intial_formula, 'initial', iter=n))\n",
    "            tasks.append(recurring_task)\n",
    "            tasks.append(initial_task)\n",
    "\n",
    "    print(GREEN + 'All Tasks Added to Queue' + RESET)\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(GREEN, 'All Tasks Completed' + RESET)\n",
    "    print(GREEN, 'Holding majority vote' + RESET)\n",
    "    results = majority_vote(results)\n",
    "    print(GREEN, 'Majority vote complete' + RESET)\n",
    "\n",
    "    for service in services:\n",
    "        name = service.dict['Name']\n",
    "        for result in results:\n",
    "            if name == result['name'] and result['type'] == 'recurring':\n",
    "                service.dict['Recurring Price'] = result['answer']\n",
    "            if name == result['name'] and result['type'] == 'initial':\n",
    "                service.dict['Initial Price'] = result['answer']\n",
    "    \n",
    "    service_offers_formatted = \"\"\n",
    "    for service in services:\n",
    "        service_offers_formatted += service.dict['Outward Facing'] + '\\n'\n",
    "        service_offers_formatted += 'Initial Price: $' + service.dict['Initial Price'] + '\\n'\n",
    "        service_offers_formatted += 'Recurring Price: $' + service.dict['Recurring Price'] + '\\n'\n",
    "        service_offers_formatted += 'Description: ' + service.dict['Description'] + '\\n'\n",
    "        service_offers_formatted += 'Covered Pests: ' + service.dict['Covered Pests'] + '\\n'\n",
    "        service_offers_formatted += 'Best For: ' + service.dict['Best for'] + '\\n'\n",
    "        service_offers_formatted += 'Frequency: ' + service.dict['Frequency'] + '\\n'\n",
    "        service_offers_formatted += 'Level of Protection: ' + service.dict['Level of Protection'] + '\\n'\n",
    "        service_offers_formatted += 'Benefits: ' + service.dict['Benefits'] + '\\n'\n",
    "        service_offers_formatted += 'Payment Link: <pay:' + service.dict['Name'] + '>\\n'\n",
    "        service_offers_formatted += '\\n'\n",
    "\n",
    "    return { \"complete_services\": services, \"service_offers_formatted\": service_offers_formatted }\n",
    "\n",
    "def add_prices(inputs):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    nest_asyncio.apply(loop)\n",
    "    response = loop.run_until_complete(get_pricing(inputs))\n",
    "    return { \"complete_services\": response[\"complete_services\"], \"service_offers_formatted\": response['service_offers_formatted'] }\n",
    "\n",
    "\n",
    "calculate_prices_chain = TransformChain(\n",
    "    transform=add_prices, \n",
    "    input_variables=[\"relevant_services_dict\"], \n",
    "    output_variables=[\"complete_services\", \"service_offers_formatted\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_template = \"\"\"You are an expert and friendly salesperson for a pest control company company. You have just finished collecting information from the customer. Provide a helpful and entertaining explaination of the best service you found for them based on the following service and issue. Use informal language. Focus on service benefits and avoid being overly technical. Be casual and pretend you are chatting with a friend. Avoid using several emojis. Be brief because this is a chatbot conversation. Customize your explaination of the offer to the customer's situation. At the end include the payment link. When selecting a service, here are your priorties:\n",
    "1. Avoid selling too much more than the customer needs \n",
    "2. Try to sell an ongoing plan whereever possible unless the customer says they don't want one\n",
    "3. Try a more expensive plan first if you think the customer can afford it\n",
    "Continue the conversation with the customer.\n",
    "Your Analysis: {siutation_analysis}\n",
    "Conversation So Far: \n",
    "{conversation_history}\n",
    "Services you can choose from: \n",
    "{service_offers_formatted}\n",
    "Your pitch:\n",
    "\"\"\"\n",
    "\n",
    "parser_prompt = PromptTemplate(template=pitch_template, input_variables=[\"conversation_history\", \"service_offers_formatted\", \"siutation_analysis\"])\n",
    "sales_pitch_chain = LLMChain(llm=gpt4, prompt=parser_prompt, output_key=\"pitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Payments:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "    \n",
    "    def create_payment_link(self, service_id, initial):\n",
    "        stripe.api_key = self.api_key\n",
    "        unit_amount = int(initial * 100)\n",
    "        #create the price for the service in the stripe dashboard\n",
    "        price = stripe.Price.create(currency=\"usd\", unit_amount=unit_amount, product=service_id)\n",
    "        price_id = price.id\n",
    "        #create the payment link\n",
    "        link = stripe.checkout.Session.create(\n",
    "            payment_method_types=['card'],\n",
    "            line_items=[\n",
    "                {\n",
    "                    'price': price_id,\n",
    "                    'quantity': 1,\n",
    "                },\n",
    "            ],\n",
    "            mode='payment',\n",
    "            success_url='https://example.com/success',\n",
    "            cancel_url='https://example.com/cancel',\n",
    "        )\n",
    "        return link.url\n",
    "\n",
    "\n",
    "pay = Payments(api_key=os.getenv('STRIPE_KEY'))\n",
    "\n",
    "def add_payment_links(inputs):\n",
    "    print('STEP: Getting payment links from stripe')\n",
    "    services = inputs[\"complete_services\"]\n",
    "    updated_services = []\n",
    "    for service in services:\n",
    "        service_id = service.dict['Service ID']\n",
    "        initial = float(service.dict['Initial Price'])\n",
    "        if initial == 0:\n",
    "            initial = float(service.dict['Recurring Price'])\n",
    "        link = pay.create_payment_link(service_id, initial)\n",
    "        service.dict['Payment Link'] = link\n",
    "        updated_services.append(service)\n",
    "    \n",
    "    print('STEP: Payment links added to services')\n",
    "    print('STEP: Creating pitch')\n",
    "    return { \"complete_services_with_links\": updated_services }\n",
    "\n",
    "payment_links_chain = TransformChain(\n",
    "    transform=add_payment_links,\n",
    "    input_variables=[\"complete_services\"],\n",
    "    output_variables=[\"complete_services_with_links\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pitch(inputs):\n",
    "    print(GREEN, 'STEP: Pitch complete' + RESET)\n",
    "    print(GREEN, 'Adding payment link to pitch' + RESET)\n",
    "    pitch = inputs[\"pitch\"]\n",
    "    #find the string in the form of <pay:service_name>\n",
    "    payment_link = re.search(r'<pay:(.*?)>', pitch)\n",
    "    if payment_link:\n",
    "        print(GREEN, 'Found payment link' + RESET)\n",
    "        program_name = payment_link.group(1).strip()\n",
    "    else:\n",
    "        print(RED, 'No payment link found' + RESET)\n",
    "        program_name = ''\n",
    "    #find the service that matches the name\n",
    "    services = inputs[\"complete_services_with_links\"]\n",
    "    payment_link = \"http://error.com\"\n",
    "    for service in services:\n",
    "        if service.dict['Name'] == program_name:\n",
    "            payment_link = service.dict['Payment Link']\n",
    "    \n",
    "    #replace the string with the payment link\n",
    "    pitch = re.sub(r'<pay:(.*?)>', payment_link, pitch)\n",
    "    print(GREEN, 'Payment link added' + RESET)\n",
    "    return { \"final pitch\": pitch }\n",
    "\n",
    "parse_pitch_chain = TransformChain(\n",
    "    transform=parse_pitch,\n",
    "    input_variables=[\"pitch\", \"complete_services\"],\n",
    "    output_variables=[\"final pitch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_situation_sequential = SequentialChain(\n",
    "    chains=[\n",
    "        retrieve_situational_awareness,\n",
    "        analyze_issue_chain,\n",
    "        get_relevant_services_chain,\n",
    "        calculate_prices_chain,\n",
    "        payment_links_chain,\n",
    "        sales_pitch_chain,\n",
    "        parse_pitch_chain\n",
    "    ],\n",
    "    input_variables=[\"square_footage\", \"property_type\", \"acres\", \"target\", \"severity\", \"conversation_history\"],\n",
    "    output_variables=[\n",
    "        \"situational_experience\", \n",
    "        \"siutation_analysis\", \n",
    "        \"relevant_services_dict\",\n",
    "        \"complete_services\",\n",
    "        \"service_offers_formatted\",\n",
    "        \"pitch\",\n",
    "        \"final pitch\"\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"\"\"\n",
    "Lead: I am looking for a one time ant treatment.\n",
    "Agent: Oh no! I'm sorry to hear that John. Luckily we can help with that :) Would you mind if I asked you a few questions so I can get a handle on your issue?\n",
    "Lead: Sure, go ahead.\n",
    "Agent: Great thanks! First how long has this been going on?\n",
    "Lead: 2 Weeks\n",
    "Agent: And how many ants are you seeing?\n",
    "Lead: A lot! They are all over the kitchen.\n",
    "Agent: OK don't worry I see this kind of thing all the time. How big is your house?\n",
    "Lead: 2000 square feet\n",
    "Agent: Got it. Give me just a second and let me run some numbers for you.\n",
    "Agent: OK here's what I'm thinking:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\u001b[92mSTEP: Getting situational experiences\u001b[0m\n",
      "\u001b[91mSituational experiences found:  ['Ants can be well managed by bimonthly service frequencies. It is less advisable, but still an option to allow customers to use quarterly services. Monthly services are often overkill for ant issues.', 'Ants can be well managed by bimonthly service frequencies. It is less advisable, but still an option to allow customers to use quarterly services. Monthly services are often overkill for ant issues.', 'Ants can be well managed by bimonthly service frequencies. It is less advisable, but still an option to allow customers to use quarterly services. Monthly services are often overkill for ant issues.', 'Ants will frequently come back and customers will benefit from ongoing services. One time services are not advisable but can be offered only if the customer doesn’t want a plan.', 'Ants will frequently come back and customers will benefit from ongoing services. One time services are not advisable but can be offered only if the customer doesn’t want a plan.'] \u001b[0m\n",
      "\u001b[92mSTEP: Analyzing situational experiences\u001b[0m\n",
      "\u001b[92mSTEP: Getting relevant services\u001b[0m\n",
      "\u001b[91mSTEP: Completed getting services:  [<__main__.Program object at 0x128351370>, <__main__.Program object at 0x13fd57e80>] \u001b[0m\n",
      "\u001b[92mSTEP: Begin parsing the formulas\u001b[0m\n",
      "\u001b[92mSTEP: Completed parsing the formulas\u001b[0m\n",
      "\u001b[92mSTEP: Generating recurring price\u001b[0m\n",
      "\u001b[92mAll Tasks Added to Queue\u001b[0m\n",
      "\u001b[1m Thinking: The first condition is always true, so the value returned will be 199. No other conditions need to be checked. \n",
      "\n",
      "Answer: 199 \u001b[0m\n",
      "\u001b[1m Thinking: \"high\"=\"high\" is true so the answer is 199. No need to evaluate the nested if statement.\n",
      "Answer: 199 \u001b[0m\n",
      "\u001b[1m Thinking: \n",
      "The first comparison \"high\"=\"high\" is true, so the formula moves on to the first output value which is 199. No need to check the second condition. \n",
      "Answer: 199 \u001b[0m\n",
      "\u001b[1m Thinking: The switch function searches for the word \"ants\" and returns 75. Since there is no match for 2000 in the nested if statement, it returns 5. Adding 75 and 5 gives a result of 80.\n",
      "Answer: 80 \u001b[0m\n",
      "\u001b[1m Thinking: \"high\" is equal to \"high\" so the first condition is true and the result is 199, otherwise it checks if \"high\" is equal to \"medium\" and if yes then the result is 149, otherwise, the result is 0.\n",
      "Answer: 199 \u001b[0m\n",
      "\u001b[1m Thinking: The switch function evaluates \"ants\" and gives a value of 75. Then, the if function is evaluated with the first condition being false, so it moves on to the second condition where 2000 is less than 4000, so it returns 5. Finally, we add 75+5=80.\n",
      "Answer: 80 \u001b[0m\n",
      "\u001b[1m Thinking: We are using the switch function to match the given string with the corresponding values. \"ants\" and \"spiders\" both match with 75, \"roaches\" match with 90, \"rats\" and \"mice\" both match with 85, \"millipedes\" and \"centipedes\" both match with 75. Then, we use the if function to check if 2000 is greater than or equal to 4000, which is false, so we move on to the second if function. 2000 is not greater than or equal to 2500, so the answer for the if statement is 0. Finally, we add the result of switch function (which is 75) with the result of the if statement (which is 0) to get the final answer.\n",
      "\n",
      "Answer: 75 \u001b[0m\n",
      "\u001b[1m Thinking: \n",
      "1. The formula uses the SWITCH function to return a value based on a given string. In this case, the formula will return 75 because \"ants\" matches the first condition in the function. \n",
      "\n",
      "2. The formula then adds the result of an IF function. The first condition checks if 2000 is greater than or equal to 4000, which is false. This means the IF function moves on to the next condition. The second condition checks if 2000 is greater than or equal to 2500, which is also false. Therefore, the IF function returns 0. \n",
      "\n",
      "3. Finally, the formula adds the result of the SWITCH function (which is 75) to the result of the IF function (which is 0). This gives us a final value of 75. \n",
      "\n",
      "Answer: 75 \u001b[0m\n",
      "\u001b[92m All Tasks Completed\u001b[0m\n",
      "\u001b[92m Holding majority vote\u001b[0m\n",
      "\u001b[92m Majority vote complete\u001b[0m\n",
      "STEP: Getting payment links from stripe\n",
      "STEP: Payment links added to services\n",
      "STEP: Creating pitch\n",
      "\u001b[92m STEP: Pitch complete\u001b[0m\n",
      "\u001b[92m Adding payment link to pitch\u001b[0m\n",
      "\u001b[92m Found payment link\u001b[0m\n",
      "\u001b[92m Payment link added\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = analyze_situation_sequential({\n",
    "    \"property_type\": \"single family\",\n",
    "    \"square_footage\": 2000,\n",
    "    \"acres\": 1,\n",
    "    \"target\": \"ants\",\n",
    "    \"severity\": \"high\",\n",
    "    \"conversation_history\": conversation\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Castle Program\n",
      "Initial Price: $199\n",
      "Recurring Price: $75\n",
      "Description: Bimonthly pest control program covering pests and proactive rodent issues.\n",
      "Covered Pests: ants, spiders, mild or moderate rodent issues, millipedes, mild roaches issues, crickets, centipedes\n",
      "Best For: The best pest control issues like ants, spiders, millipedes, centipedes\n",
      "Frequency: Bimonthly year round\n",
      "Level of Protection: Average\n",
      "Benefits: Proactive annual termite inspection reduces the risk of having termites for years undetected; Year-round Proactive Coverage for 33 pests: bimonthly pest forms a protective barrier around your home, adding extra prevention for termites and pests; One bill on autopilot\n",
      "Payment Link: <pay:Program 2>\n",
      "\n",
      "Castle Program\n",
      "Initial Price: $199\n",
      "Recurring Price: $75\n",
      "Description: Bimonthly pest control program covering pests and proactive rodent issues.\n",
      "Covered Pests: ants, spiders, mild or moderate rodent issues, millipedes, mild roaches issues, crickets, centipedes\n",
      "Best For: The best pest control issues like ants, spiders, millipedes, centipedes\n",
      "Frequency: Bimonthly year round\n",
      "Level of Protection: Average\n",
      "Benefits: Proactive annual termite inspection reduces the risk of having termites for years undetected; Year-round Proactive Coverage for 33 pests: bimonthly pest forms a protective barrier around your home, adding extra prevention for termites and pests; One bill on autopilot\n",
      "Payment Link: <pay:Program 2>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['service_offers_formatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['customer_issue',\n",
    " 'customer_preferences',\n",
    " 'property_type',\n",
    " 'square_footage',\n",
    " 'acres',\n",
    " 'target',\n",
    " 'severity',\n",
    " 'situational_experience',\n",
    " 'siutation_analysis',\n",
    " 'service_search_term',\n",
    " 'services_plain_text',\n",
    " 'thinking_through_service_rankings',\n",
    " 'service_id_list',\n",
    " 'service_ids',\n",
    " 'offers',\n",
    " 'recurring_formula_parsed',\n",
    " 'initial_formula_parsed',\n",
    " 'recurring_logic',\n",
    " 'initial_logic',\n",
    " 'recurring_price',\n",
    " 'initial_price',\n",
    " 'pitch']\n",
    "\n",
    "def observe_steps(steps, start, num_steps):\n",
    "    step_list = [\n",
    "        f'Inputs: Customer Issues: {steps[\"customer_issue\"]}\\nCustomer Preferences: {steps[\"customer_preferences\"]}\\nProperty Type: {steps[\"property_type\"]}\\nSquare Footage: {steps[\"square_footage\"]}\\nAcres: {steps[\"acres\"]}\\nTarget: {steps[\"target\"]}\\nSeverity: {steps[\"severity\"]}',\n",
    "        f'situational_experience: {steps[\"situational_experience\"]}',\n",
    "        f'siutation_analysis: {steps[\"siutation_analysis\"]}',\n",
    "        f'service_search_term: {steps[\"service_search_term\"]}',\n",
    "        f'services_plain_text: {steps[\"services_plain_text\"]}',\n",
    "        f'thinking_through_service_rankings: {steps[\"thinking_through_service_rankings\"]}',\n",
    "        f'service_id_list: {steps[\"service_id_list\"]}',\n",
    "        f'service_ids: {steps[\"service_ids\"]}',\n",
    "        f'offers: {steps[\"offers\"]}',\n",
    "        f'recurring_formula_parsed: {steps[\"recurring_formula_parsed\"]}',\n",
    "        f'recurring_logic: {steps[\"recurring_logic\"]}',\n",
    "        f'recurring_price: {steps[\"recurring_price\"]}',\n",
    "        f'initial_formula_parsed: {steps[\"initial_formula_parsed\"]}',\n",
    "        f'initial_logic: {steps[\"initial_logic\"]}',\n",
    "        f'initial_price: {steps[\"initial_price\"]}',\n",
    "        f'pitch: {steps[\"pitch\"]}'\n",
    "    ]\n",
    "\n",
    "    end = start + num_steps\n",
    "    list = step_list[start:end]\n",
    "    for i in list:\n",
    "        print(i)\n",
    "        print('-----------------')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec0f111f5e5040c678ec5a567f7682a80a3d7b8519cf7f13b3475890ed8a264f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
